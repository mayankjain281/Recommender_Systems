{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.26.4'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# !pip uninstall\n",
    "# !pip install numpy==1.26.4\n",
    "np.version.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\mayan\\\\Desktop\\\\Portfolio Projects\\\\Recommender_Systems\\\\Zee_Movies_Recommender'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-21T12:36:31.348105Z",
     "iopub.status.busy": "2021-06-21T12:36:31.347717Z",
     "iopub.status.idle": "2021-06-21T12:36:32.003856Z",
     "shell.execute_reply": "2021-06-21T12:36:32.002744Z",
     "shell.execute_reply.started": "2021-06-21T12:36:31.348073Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "movies = pd.read_csv('tmdb_5000_movies.csv')\n",
    "credits = pd.read_csv('tmdb_5000_credits.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-21T12:36:38.687005Z",
     "iopub.status.busy": "2021-06-21T12:36:38.686521Z",
     "iopub.status.idle": "2021-06-21T12:36:38.713343Z",
     "shell.execute_reply": "2021-06-21T12:36:38.711939Z",
     "shell.execute_reply.started": "2021-06-21T12:36:38.686963Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "movies = movies.merge(credits,on='title')\n",
    "movies = movies[['movie_id','title','overview','genres','keywords','cast','crew']]\n",
    "movies.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello', ',', 'world', '!', 'I', 'do', \"n't\", 'know', '.']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# text.split() → quick & dirty\n",
    "# word_tokenize(text) → clean, robust, NLP-ready\n",
    "# If you’re doing POS tagging, lemmatization, or semantic vectorization, always use word_tokenize()\n",
    "\n",
    "import nltk\n",
    "# nltk.download('punkt')\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "word_tokenize(\"Hello, world! I don't know.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-21T12:34:19.382856Z",
     "iopub.status.busy": "2021-06-21T12:34:19.382331Z",
     "iopub.status.idle": "2021-06-21T12:34:19.387416Z",
     "shell.execute_reply": "2021-06-21T12:34:19.386451Z",
     "shell.execute_reply.started": "2021-06-21T12:34:19.382822Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# If you use pretrained embeddings (e.g., Word2Vec, BERT, SentenceTransformers):\n",
    "# Then skip stemming/lemmatization\n",
    "# Because those models already understand word forms and context — modifying words can hurt semantic meaning.\n",
    "# However, removing stopwords and lowercasing can still help reduce noise. (but countvectors or tfidf automatically handle lowercasing and stopwords)\n",
    "# You should not remove alphnumeric or numeric characters as some movie names or keywords may contain them\n",
    "\n",
    "# By default, WordNet Lemmatizer assumes words to be nouns. For more accurate lemmatization, especially for verbs and adjectives, Part of Speech (POS) tagging is required.\n",
    "# https://www.geeksforgeeks.org/machine-learning/python-lemmatization-approaches-with-examples/\n",
    "# https://www.geeksforgeeks.org/nlp/nlp-part-of-speech-default-tagging/\n",
    "\n",
    "\n",
    "import nltk\n",
    "from nltk import pos_tag\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import wordnet, stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "# Download required NLTK data (run once)\n",
    "\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('averaged_perceptron_tagger')\n",
    "# nltk.download('wordnet')\n",
    "# nltk.download('stopwords')\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def clean_and_lemmatize(text):\n",
    "\n",
    "    # Lowercase + remove non-alphabetic characters\n",
    "    # text = re.sub(r'[^a-zA-Z\\s]', ' ', text.lower())\n",
    "    \n",
    "    # Tokenize\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # Remove stopwords\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    \n",
    "    # POS tagging\n",
    "    tagged = pos_tag(tokens)\n",
    "    \n",
    "    # Lemmatize with POS\n",
    "    lemmatized = [\n",
    "        lemmatizer.lemmatize(word, pos='v' if tag.startswith('V') else 'n')\n",
    "        for word, tag in tagged\n",
    "    ]\n",
    "    \n",
    "    return lemmatized\n",
    "\n",
    "\n",
    "movies['overview'] = movies['overview'].apply(clean_and_lemmatize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-21T12:36:47.540453Z",
     "iopub.status.busy": "2021-06-21T12:36:47.539904Z",
     "iopub.status.idle": "2021-06-21T12:36:47.545014Z",
     "shell.execute_reply": "2021-06-21T12:36:47.544243Z",
     "shell.execute_reply.started": "2021-06-21T12:36:47.540418Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'id': 28, 'name': 'Action'}, {'id': 12, 'name': 'Adventure'}, {'id': 14, 'name': 'Fantasy'}, {'id': 878, 'name': 'Science Fiction'}]\n"
     ]
    }
   ],
   "source": [
    "# Below function converts string to list\n",
    "\n",
    "import ast\n",
    "\n",
    "def convert(text):\n",
    "    L = []\n",
    "    for i in ast.literal_eval(text):\n",
    "        L.append(i['name']) \n",
    "    return L \n",
    "\n",
    "print(ast.literal_eval('[{\"id\": 28, \"name\": \"Action\"}, {\"id\": 12, \"name\": \"Adventure\"}, {\"id\": 14, \"name\": \"Fantasy\"}, {\"id\": 878, \"name\": \"Science Fiction\"}]'))\n",
    "\n",
    "movies['genres'] = movies['genres'].apply(convert)\n",
    "movies['keywords'] = movies['keywords'].apply(convert)\n",
    "movies['cast'] = movies['cast'].apply(convert)\n",
    "movies['cast'] = movies['cast'].apply(lambda x:x[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-21T12:37:09.763317Z",
     "iopub.status.busy": "2021-06-21T12:37:09.762909Z",
     "iopub.status.idle": "2021-06-21T12:37:09.770917Z",
     "shell.execute_reply": "2021-06-21T12:37:09.770002Z",
     "shell.execute_reply.started": "2021-06-21T12:37:09.763278Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def fetch_director(text):\n",
    "    L = []\n",
    "    for i in ast.literal_eval(text):\n",
    "        if i['job'] == 'Director':\n",
    "            L.append(i['name'])\n",
    "    return L \n",
    "\n",
    "movies['crew'] = movies['crew'].apply(fetch_director)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-21T12:35:23.278589Z",
     "iopub.status.busy": "2021-06-21T12:35:23.278025Z",
     "iopub.status.idle": "2021-06-21T12:35:23.311346Z",
     "shell.execute_reply": "2021-06-21T12:35:23.309971Z",
     "shell.execute_reply.started": "2021-06-21T12:35:23.278539Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_id</th>\n",
       "      <th>title</th>\n",
       "      <th>overview</th>\n",
       "      <th>genres</th>\n",
       "      <th>keywords</th>\n",
       "      <th>cast</th>\n",
       "      <th>crew</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19995</td>\n",
       "      <td>Avatar</td>\n",
       "      <td>[In, 22nd, century, ,, paraplegic, Marine, dis...</td>\n",
       "      <td>[Action, Adventure, Fantasy, ScienceFiction]</td>\n",
       "      <td>[cultureclash, future, spacewar, spacecolony, ...</td>\n",
       "      <td>[SamWorthington, ZoeSaldana, SigourneyWeaver, ...</td>\n",
       "      <td>[JamesCameron]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>285</td>\n",
       "      <td>Pirates of the Caribbean: At World's End</td>\n",
       "      <td>[Captain, Barbossa, ,, long, believe, dead, ,,...</td>\n",
       "      <td>[Adventure, Fantasy, Action]</td>\n",
       "      <td>[ocean, drugabuse, exoticisland, eastindiatrad...</td>\n",
       "      <td>[JohnnyDepp, OrlandoBloom, KeiraKnightley, Ste...</td>\n",
       "      <td>[GoreVerbinski]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>206647</td>\n",
       "      <td>Spectre</td>\n",
       "      <td>[A, cryptic, message, Bond, ’, past, sends, tr...</td>\n",
       "      <td>[Action, Adventure, Crime]</td>\n",
       "      <td>[spy, basedonnovel, secretagent, sequel, mi6, ...</td>\n",
       "      <td>[DanielCraig, ChristophWaltz, LéaSeydoux, Ralp...</td>\n",
       "      <td>[SamMendes]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>49026</td>\n",
       "      <td>The Dark Knight Rises</td>\n",
       "      <td>[Following, death, District, Attorney, Harvey,...</td>\n",
       "      <td>[Action, Crime, Drama, Thriller]</td>\n",
       "      <td>[dccomics, crimefighter, terrorist, secretiden...</td>\n",
       "      <td>[ChristianBale, MichaelCaine, GaryOldman, Anne...</td>\n",
       "      <td>[ChristopherNolan]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>49529</td>\n",
       "      <td>John Carter</td>\n",
       "      <td>[John, Carter, war-weary, ,, former, military,...</td>\n",
       "      <td>[Action, Adventure, ScienceFiction]</td>\n",
       "      <td>[basedonnovel, mars, medallion, spacetravel, p...</td>\n",
       "      <td>[TaylorKitsch, LynnCollins, SamanthaMorton, Wi...</td>\n",
       "      <td>[AndrewStanton]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movie_id                                     title  \\\n",
       "0     19995                                    Avatar   \n",
       "1       285  Pirates of the Caribbean: At World's End   \n",
       "2    206647                                   Spectre   \n",
       "3     49026                     The Dark Knight Rises   \n",
       "4     49529                               John Carter   \n",
       "\n",
       "                                            overview  \\\n",
       "0  [In, 22nd, century, ,, paraplegic, Marine, dis...   \n",
       "1  [Captain, Barbossa, ,, long, believe, dead, ,,...   \n",
       "2  [A, cryptic, message, Bond, ’, past, sends, tr...   \n",
       "3  [Following, death, District, Attorney, Harvey,...   \n",
       "4  [John, Carter, war-weary, ,, former, military,...   \n",
       "\n",
       "                                         genres  \\\n",
       "0  [Action, Adventure, Fantasy, ScienceFiction]   \n",
       "1                  [Adventure, Fantasy, Action]   \n",
       "2                    [Action, Adventure, Crime]   \n",
       "3              [Action, Crime, Drama, Thriller]   \n",
       "4           [Action, Adventure, ScienceFiction]   \n",
       "\n",
       "                                            keywords  \\\n",
       "0  [cultureclash, future, spacewar, spacecolony, ...   \n",
       "1  [ocean, drugabuse, exoticisland, eastindiatrad...   \n",
       "2  [spy, basedonnovel, secretagent, sequel, mi6, ...   \n",
       "3  [dccomics, crimefighter, terrorist, secretiden...   \n",
       "4  [basedonnovel, mars, medallion, spacetravel, p...   \n",
       "\n",
       "                                                cast                crew  \n",
       "0  [SamWorthington, ZoeSaldana, SigourneyWeaver, ...      [JamesCameron]  \n",
       "1  [JohnnyDepp, OrlandoBloom, KeiraKnightley, Ste...     [GoreVerbinski]  \n",
       "2  [DanielCraig, ChristophWaltz, LéaSeydoux, Ralp...         [SamMendes]  \n",
       "3  [ChristianBale, MichaelCaine, GaryOldman, Anne...  [ChristopherNolan]  \n",
       "4  [TaylorKitsch, LynnCollins, SamanthaMorton, Wi...     [AndrewStanton]  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies['cast'] = movies['cast'].apply(lambda x: [i.replace(\" \",\"\") for i in x])\n",
    "movies['crew'] = movies['crew'].apply(lambda x: [i.replace(\" \",\"\") for i in x])\n",
    "movies['genres'] = movies['genres'].apply(lambda x: [i.replace(\" \",\"\") for i in x])\n",
    "movies['keywords'] = movies['keywords'].apply(lambda x: [i.replace(\" \",\"\") for i in x])\n",
    "\n",
    "# def collapse(L):\n",
    "#     L1 = []\n",
    "#     for i in L:\n",
    "#         L1.append(i.replace(\" \",\"\"))\n",
    "#     return L1\n",
    "# movies['cast'] = movies['cast'].apply(collapse)\n",
    "\n",
    "movies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-21T12:37:34.466349Z",
     "iopub.status.busy": "2021-06-21T12:37:34.465925Z",
     "iopub.status.idle": "2021-06-21T12:37:34.572742Z",
     "shell.execute_reply": "2021-06-21T12:37:34.571676Z",
     "shell.execute_reply.started": "2021-06-21T12:37:34.466313Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_id</th>\n",
       "      <th>title</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19995</td>\n",
       "      <td>Avatar</td>\n",
       "      <td>In 22nd century , paraplegic Marine dispatch m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>285</td>\n",
       "      <td>Pirates of the Caribbean: At World's End</td>\n",
       "      <td>Captain Barbossa , long believe dead , come ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>206647</td>\n",
       "      <td>Spectre</td>\n",
       "      <td>A cryptic message Bond ’ past sends trail unco...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>49026</td>\n",
       "      <td>The Dark Knight Rises</td>\n",
       "      <td>Following death District Attorney Harvey Dent ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>49529</td>\n",
       "      <td>John Carter</td>\n",
       "      <td>John Carter war-weary , former military captai...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movie_id                                     title  \\\n",
       "0     19995                                    Avatar   \n",
       "1       285  Pirates of the Caribbean: At World's End   \n",
       "2    206647                                   Spectre   \n",
       "3     49026                     The Dark Knight Rises   \n",
       "4     49529                               John Carter   \n",
       "\n",
       "                                                tags  \n",
       "0  In 22nd century , paraplegic Marine dispatch m...  \n",
       "1  Captain Barbossa , long believe dead , come ba...  \n",
       "2  A cryptic message Bond ’ past sends trail unco...  \n",
       "3  Following death District Attorney Harvey Dent ...  \n",
       "4  John Carter war-weary , former military captai...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies['tags'] = movies['overview'] + movies['genres'] + movies['keywords'] + movies['cast'] + movies['crew']\n",
    "new = movies.drop(columns=['overview','genres','keywords','cast','crew'])\n",
    "new['tags'] = new['tags'].apply(lambda x: \" \".join(x))\n",
    "\n",
    "new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-21T12:38:06.545110Z",
     "iopub.status.busy": "2021-06-21T12:38:06.544599Z",
     "iopub.status.idle": "2021-06-21T12:38:07.488307Z",
     "shell.execute_reply": "2021-06-21T12:38:07.487238Z",
     "shell.execute_reply.started": "2021-06-21T12:38:06.545079Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# CountVectorizer is giving better results than TfidfVectorizer in this case\n",
    "# You should not remove alphnumeric or numeric characters as some movie names or keywords may contain them\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer(max_features=5000,stop_words='english')\n",
    "vectors = vectorizer.fit_transform(new['tags']).toarray()\n",
    "\n",
    "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# vectorizer = TfidfVectorizer(stop_words='english', max_features=5000)\n",
    "# vectors = vectorizer.fit_transform(new['tags']).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['000',\n",
       " '007',\n",
       " '10',\n",
       " '100',\n",
       " '11',\n",
       " '12',\n",
       " '13',\n",
       " '14',\n",
       " '15',\n",
       " '16',\n",
       " '17',\n",
       " '18',\n",
       " '18th',\n",
       " '19',\n",
       " '1930s',\n",
       " '1940s',\n",
       " '1950s',\n",
       " '1960s',\n",
       " '1970s',\n",
       " '1980']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(vectorizer.get_feature_names_out())[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-21T12:38:13.339451Z",
     "iopub.status.busy": "2021-06-21T12:38:13.339041Z",
     "iopub.status.idle": "2021-06-21T12:38:13.390575Z",
     "shell.execute_reply": "2021-06-21T12:38:13.389373Z",
     "shell.execute_reply.started": "2021-06-21T12:38:13.339412Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "similarity = cosine_similarity(vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.08346223, 0.0860309 , ..., 0.04588315, 0.0270369 ,\n",
       "        0.        ],\n",
       "       [0.08346223, 1.        , 0.06063391, ..., 0.04850713, 0.        ,\n",
       "        0.        ],\n",
       "       [0.0860309 , 0.06063391, 1.        , ..., 0.05      , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.04588315, 0.04850713, 0.05      , ..., 1.        , 0.07071068,\n",
       "        0.04417261],\n",
       "       [0.0270369 , 0.        , 0.        , ..., 0.07071068, 1.        ,\n",
       "        0.05205792],\n",
       "       [0.        , 0.        , 0.        , ..., 0.04417261, 0.05205792,\n",
       "        1.        ]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-19T14:08:46.716222Z",
     "iopub.status.busy": "2021-06-19T14:08:46.7159Z",
     "iopub.status.idle": "2021-06-19T14:08:46.7239Z",
     "shell.execute_reply": "2021-06-19T14:08:46.722946Z",
     "shell.execute_reply.started": "2021-06-19T14:08:46.716196Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "744"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new[new['title'] == 'The Lego Movie'].index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-21T12:38:22.542900Z",
     "iopub.status.busy": "2021-06-21T12:38:22.542487Z",
     "iopub.status.idle": "2021-06-21T12:38:22.549786Z",
     "shell.execute_reply": "2021-06-21T12:38:22.548271Z",
     "shell.execute_reply.started": "2021-06-21T12:38:22.542867Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def recommend(movie):\n",
    "    index = new[new['title'] == movie].index[0]\n",
    "    distances = sorted(list(enumerate(similarity[index])),reverse=True,key = lambda x: x[1])\n",
    "    for i in distances[1:6]:\n",
    "        print(new.iloc[i[0]].title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Notebook\n",
      "Ghost Ship\n",
      "Captain Phillips\n",
      "Poseidon\n",
      "Supernova\n"
     ]
    }
   ],
   "source": [
    "recommend('Titanic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Fall of the Roman Empire\n",
      "Coriolanus\n",
      "The Heart of Me\n",
      "Pompeii\n",
      "The House of Mirth\n"
     ]
    }
   ],
   "source": [
    "recommend('Yeh Jawaani Hai Deewani')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gandhi, My Father\n",
      "The Wind That Shakes the Barley\n",
      "A Passage to India\n",
      "Guiana 1838\n",
      "Ramanujan\n"
     ]
    }
   ],
   "source": [
    "recommend('Gandhi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-21T12:40:53.373581Z",
     "iopub.status.busy": "2021-06-21T12:40:53.373186Z",
     "iopub.status.idle": "2021-06-21T12:40:53.784869Z",
     "shell.execute_reply": "2021-06-21T12:40:53.783635Z",
     "shell.execute_reply.started": "2021-06-21T12:40:53.373547Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pickle, gzip\n",
    "pickle.dump(new,open('movie_list.pkl','wb'))\n",
    "# pickle.dump(similarity,open('similarity.pkl','wb'))\n",
    "\n",
    "with gzip.open(\"similarity.pkl.gz\", \"wb\") as f:\n",
    "    pickle.dump(similarity, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for loading compressed file\n",
    "\n",
    "# import gzip, pickle\n",
    "# with gzip.open(\"similarity_compressed.pkl.gz\", \"rb\") as f:\n",
    "#     similarity = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Not scanning for jupyter notebooks.\n",
      "WARNING: Import named \"Requests\" not found locally. Trying to resolve it at the PyPI server.\n",
      "WARNING: Import named \"Requests\" was resolved to \"requests:2.32.5\" package (https://pypi.org/project/requests/).\n",
      "Please, verify manually the final list of requirements.txt to avoid possible dependency confusions.\n",
      "INFO: Successfully saved requirements file in .\\requirements.txt\n"
     ]
    }
   ],
   "source": [
    "# below command to generate requirements.txt\n",
    "\n",
    "# pip install pipreqs\n",
    "!pipreqs . --force\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Advanced Approach for text embeddings (pretrained models, no stemming/lemmatization needed):\n",
    "# \n",
    "# ➡️ Sentence-BERT (SBERT) — model: all-MiniLM-L6-v2\n",
    "# Captures semantic meaning of entire sentences/plots\n",
    "# Lightweight (only ~80 MB) faster than larger BERT models\n",
    "# Fast to encode thousands of movies\n",
    "# Works great with cosine_similarity\n",
    "# Used in many professional recommender systems\n",
    "\n",
    "# But we are not using it here because of resource constraints in this environment.\n",
    "# Have to install additional libraries which may not be supported here.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# from sentence_transformers import SentenceTransformer\n",
    "# from sklearn.metrics.pairwise import cosine_similarity\n",
    "# import numpy as np\n",
    "\n",
    "# model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# # Example: encode movie descriptions/tags\n",
    "# embeddings = model.encode(df['tags'].tolist(), normalize_embeddings=True)\n",
    "\n",
    "# # Compute similarity\n",
    "# similarity = cosine_similarity(embeddings)\n",
    "\n",
    "# def recommend(movie_title):\n",
    "#     idx = df[df['title'] == movie_title].index[0]\n",
    "#     distances = sorted(list(enumerate(similarity[idx])), key=lambda x: x[1], reverse=True)\n",
    "#     for i in distances[1:6]:\n",
    "#         print(df.iloc[i[0]].title)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
